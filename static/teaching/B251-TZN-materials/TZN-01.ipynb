{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cvičení 1 - Úvod do neuronových sítí\n",
    "\n",
    "V tomto cvičení si ukážeme prácis s jazykem **Python** a jeho knihovnami, především [PyTorch](https://pytorch.org/).\n",
    "\n",
    "Obdobným způsobem se pracuje i s dalšími používanými knihovnami jako např. [TensorFlow](https://www.tensorflow.org/), [JAX](https://docs.jax.dev/en/latest/), [Flux.jl](https://fluxml.ai/) nebo [Deep Learning Toolbox](https://www.mathworks.com/products/deep-learning.html).\n",
    "\n",
    "Pro detailnější tutoriál k PyTorch jsou dostupné i [oficiální tutoriály](https://pytorch.org/tutorials/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instalace v prostředí uv a Jupyter\n",
    "\n",
    "Nainstalujeme Jupyter dle pokynů z [webu](https://jupyter.org/install). Obdobně s balíčkovacím systémem [uv](https://docs.astral.sh/uv/).\n",
    "\n",
    "Vytvoříme uv balíček a propojíme ho s Jupyterem\n",
    "```bash\n",
    "$ uv init\n",
    "$ uv add --dev ipykernel\n",
    "$ uv run ipython kernel install --user --env VIRTUAL_ENV $(pwd)/.venv --name=tzn\n",
    "```\n",
    "\n",
    "Pro dostupnost tohoto kernelu musíme restartovat Jupyter.\n",
    "\n",
    "Nainstalujeme potřebné balíčky\n",
    "\n",
    "```bash\n",
    "$ uv add matplotlib numpy scikit-learn torch torch-geometric torchvision\n",
    "$ uv add torch-cluster -f https://data.pyg.org/whl/torch-2.8.0+cpu.html\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Úkol 1\n",
    "\n",
    "Zprovozněte své prostředí tak, aby se následující buňka spustila bez chyb a zobrazila něco jako `Torch version: 2.8.0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "print(\"Torch version:\", torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tenzory a práce s nimi v PyTorch\n",
    "\n",
    "Nejprve se podívejme na to, co se vlastně při standardním využití děje na pozadí - manipulace s tenzory a automatické počítání gradientu.\n",
    "\n",
    "Tenzor je vlastně název pro $n$ rozměrné pole - tj. jako `ndarray` v numpy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Převod numpy nebo python matice na konstantní tenzor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[1, 2], [3,4]])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Převod zpět do numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor vždy obsahuje základní atributy `shape` a `dtype`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Rozměr:', a.shape)\n",
    "print('Datový typ:', a.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Další způsoby, jak vytvořit Tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.ones((1, 3)))\n",
    "print(torch.zeros((1, 3)))\n",
    "print(torch.randn((1, 4))) # Normální rozdělení\n",
    "print(torch.rand((1, 4))) # Uniformní rozdělení na [0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "S tenzory můžeme dělat běžné operace - maticové atd. Vyrobíme si nějaké tenzory (musí být stejného datového typu):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[1, 2], [3,4]], dtype = torch.float32)\n",
    "b = torch.ones((2, 1))\n",
    "c = torch.randn((2, 1))\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maticový součin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a.matmul(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Součet po složkách:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(b.add(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kvadrát po složkách:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a.square())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eukleidovská norma vektoru:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(b.norm())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hodnost matice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.linalg.matrix_rank(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplikace funkce sinus po složkách:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.sin(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boolovský idikátor toho, zda je daná složka matice větší než 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a.greater(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Úkol 2 - základní práce s daty\n",
    "\n",
    "Načteme dataset [MNIST](https://en.wikipedia.org/wiki/MNIST_database) a zkusíme spočítat průměrné hodnoty jeho jednotlivých feature. První spuštění následující buňky může trvat déle, než se dataset stáhne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.MNIST(\n",
    "    root = \"data\",\n",
    "    download = True,\n",
    "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(0, 1)])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Načetli jsme obrázky z datasetu MNIST. Nyní zkuste spočítat průměrnou hodnotu každé feature napříč všemi obrázky. Využijte třídu [`DataLoader`](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatické počítání gradientu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objekt, který se používá na práci s proměnlivým obsahem, je standardní `torch.Tensor`. Nejzajímavější na něm je **automatické počítání gradientu** vzhledem k operacím prováděným s ním.\n",
    "\n",
    "K tomu se používá parametr `requires_grad = True`, pomocí kterého se zaznamenávají operace se sledovaným tenzorem.\n",
    "Gradient pak spočteme voláním metody `fun.backward()`, který spočte derivaci `fun` podle každé složky `x`. Pokud je `fun` tensor rozměru většího než 1, je potřeba funkci `backward` předat tensor, vzhledem ke kterému se má Jakobián spočítat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1, 2, 3], dtype = torch.float32, requires_grad = True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = torch.square(x)\n",
    "f.backward(torch.ones_like(f))\n",
    "\n",
    "print('Derivace x^2:', x.grad)\n",
    "with torch.no_grad():\n",
    "    print('2*x:', 2*x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1, 2, 3], dtype = torch.float32, requires_grad = True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = torch.sin(x)\n",
    "f.backward(torch.ones_like(f))\n",
    "    \n",
    "print('Derivace sin(x):', x.grad)\n",
    "with torch.no_grad():\n",
    "    print('cos(x):', torch.cos(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jednoduchá síť na MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definujeme základní parametry modelu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "hidden_layer_width = 100\n",
    "output_width = 10\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Připravíme si data do tříd DataLoader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = datasets.MNIST(\n",
    "    root = \"data\",\n",
    "    train = True,\n",
    "    download = True,\n",
    "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(0, 1)])\n",
    ")\n",
    "data_test = datasets.MNIST(\n",
    "    root = \"data\",\n",
    "    train = False,\n",
    "    download = True,\n",
    "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(0, 1)])\n",
    ")\n",
    "\n",
    "dataloader_train = DataLoader(data_train, batch_size = batch_size, shuffle = True)\n",
    "dataloader_test = DataLoader(data_test, batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vytvoříme jednoduchý model neuronové sítě pomocí `torch.nn.Sequential` což je třída, která za sebe poskládá vrstvy, které do ní vložíme (viz předchozí cvičení).\n",
    "\n",
    "Vstupní vrstva je typu `torch.nn.Flatten`, tedy vrstva která převede obrázky do tvaru vektoru (opět automatizace z minulého cvičení).\n",
    "\n",
    "Výslkedkem je instance [tf.nn.Module](https://pytorch.org/docs/main/generated/torch.nn.Module.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential()\n",
    "model.append(nn.Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Přidáme jednu skrytou vrstvu se 100 neurony a aktivační funkcí `tanh`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.append(nn.Linear(data_train.data.shape[1] * data_train.data.shape[2], hidden_layer_width))\n",
    "model.append(nn.Tanh())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Přidáme výstupní vrstvu s 10 neurony (= počet tříd) a aktivační funkcí softmax\n",
    "$$ \\sigma \\left( \\vec{z} \\right)_i = \\frac{e^{\\vec{z}_i}}{\\sum_{j = 1}^K e^{\\vec{z}_j}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.append(nn.Linear(hidden_layer_width, output_width))\n",
    "model.append(nn.Softmax(dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vytisknutí modelu nám vytiskne kompletní informace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Takto vytvořený model zároveň funguje jako funkce a můžeme ho rovnou aplikovat na data.\n",
    "\n",
    "Výskedkem budou vektory pravděpodobností. Protože jsme ale model zatím netrénovali, výsledky budou prakticky náhodné"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(data_train[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Výslednou \"předpověď\" modelu pak bereme jako položku s nejvyšší pravděpodobností:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "for i in range(24):\n",
    "    plt.subplot(4, 6, i + 1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(data_train[i][0].reshape(28, 28), cmap = plt.cm.bone)\n",
    "    plt.title(model(data_train[i][0]).detach().argmax(axis = 1).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trénování modelu\n",
    "\n",
    "Nyní můžeme model natrénovat. Co budeme dále potřebovat:\n",
    "* loss - ztrátová funkce, kterou chceme při trénování minimalizovat,\n",
    "* optimizer - funkce, která pracuje s gradientem a udělá krok gradientního sestupu,\n",
    "\n",
    "Poznámky:\n",
    "* `torch.nn.NLLLoss` je cross-entropie, kde vstup je pravděpodobnostní rozdělení\n",
    "* `torch.nn.CrossEntropyLoss()` je cross-entropie, kde vstup jsou váhy jednotlivých tříd (tj. jejich suma nemusí být 1)\n",
    "\n",
    "Jinými slovy `CrossEntropyLoss` kombinuje `NLLLoss` a `Softmax`.\n",
    "\n",
    "Použijeme stochastický gradientní sestup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.NLLLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K trénování modelu použijeme `DataLoader`, obdobně jako v minulém cvičení. \n",
    "Trénování v mini batchích znamená, že se dataset rozdělí na bločky (mini batche) a pak se pro každý bloček spočítá ztrátová funkce a udělá jede krok gradientního sestupu. Jedna epocha pak znamená projití celého datasetu. V jedné epoše tedy dojde k mnoha krokům gradientního sestupu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(model, dataloader):\n",
    "    num_correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for (X, y) in dataloader:\n",
    "            pred = model(X)\n",
    "            num_correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    accuracy = num_correct / len(dataloader.dataset)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss_accuracy(model, dataloader, loss_fn):\n",
    "    loss = 0\n",
    "    num_correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for (X, y) in dataloader:\n",
    "            pred = model(X)\n",
    "            loss += loss_fn(pred, y).item()\n",
    "            num_correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    loss /= len(dataloader)\n",
    "    accuracy = num_correct / len(dataloader.dataset)\n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, loss_fn, optimizer, epochs, dataloader_train, dataloader_test, early_stopper = None, log_period = 10000):\n",
    "    for epoch in range(epochs):\n",
    "        processed_since_log = 0\n",
    "        for batch, (X, y) in enumerate(dataloader_train):\n",
    "            model.train()\n",
    "            pred = model(X)\n",
    "            loss = loss_fn(pred, y)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            processed_since_log += dataloader_train.batch_size\n",
    "\n",
    "            if processed_since_log >= log_period:\n",
    "                current = min((batch + 1) * dataloader_train.batch_size, len(data_train))\n",
    "                loss = loss.item()\n",
    "                model.eval()\n",
    "                train_acc = calculate_accuracy(model, dataloader_train)\n",
    "                test_loss, test_acc = calculate_loss_accuracy(model, dataloader_test, loss_fn)\n",
    "                print(f\"train loss: {loss:>7f}  test loss: {test_loss:>7f}  train accuracy: {train_acc:>3f}  test accuracy: {test_acc:>3f}  [sample {current:>5d}/{len(data_train):>5d}] [epoch {epoch+1:>2d}/{epochs:>2d}]\")\n",
    "                processed_since_log -= log_period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(model, loss_fn, optimizer, epochs, dataloader_train, dataloader_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluace modelu a predikce\n",
    "\n",
    "K evaluaci modelu na testovací množině využijeme výše implementované funkce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_loss, test_acc = calculate_loss_accuracy(model, dataloader_test, loss_fn)\n",
    "print('Test loss:', test_loss)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pokud chceme přímo \"syrové\" hodnoty, můžeme použít model jako funkci:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model(data_test[0][0])\n",
    "print('Predictions shape:', predictions.shape)\n",
    "print('Predikce pravděpodobností pro první obrázek:', predictions[0, 0].item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pro získání predikcí tříd můžeme použít `torch.argmax`, která vrátí index maximální pravděpodobnosti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = predictions.detach().argmax(dim = 1)\n",
    "print('Predikce pravděpodobností pro první obrázek:', predictions.detach())\n",
    "print('Predikce labelu pro první obrázek:', Y_pred[0].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "for i in range(24):\n",
    "    plt.subplot(4, 6, i + 1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(data_test[i][0].reshape(28, 28), cmap = plt.cm.bone)\n",
    "    plt.title(model(data_test[i][0]).detach().argmax(axis = 1).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Úkol 3 - Manuální vytvoření modelu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definujeme základní parametry modelu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "hidden_layer_width = 100\n",
    "output_width = 10\n",
    "learning_rate = 0.01\n",
    "epochs = 10\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definuji si proměnné pro neuronovou síť s 1 skrytou vrstvou velikosti 100:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Průměr 0, směrodatná odchylka 0.1\n",
    "W1 = (0.1 * torch.randn((data_train[0][0].shape[1] * data_train[0][0].shape[2], hidden_layer_width))).clone().requires_grad_(True)\n",
    "b1 = torch.zeros((hidden_layer_width,), requires_grad = True)\n",
    "W2 = (0.1 * torch.randn((hidden_layer_width, output_width))).clone().requires_grad_(True)\n",
    "b2 = torch.zeros((output_width,), requires_grad = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definujeme funkci vykonávající dopředný chod sítě:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(inputs):\n",
    "    # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Natrénujeme model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_period = 10000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    processed_since_log = 0\n",
    "    for batch, (X, y) in enumerate(dataloader_train):\n",
    "        pred = predict(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        loss.backward()\n",
    "\n",
    "        for variable in [W1, b1, W2, b2]:\n",
    "            with torch.no_grad():\n",
    "                variable -= variable.grad * learning_rate\n",
    "            variable.grad = None\n",
    "\n",
    "        processed_since_log += dataloader_train.batch_size\n",
    "\n",
    "        if processed_since_log >= log_period:\n",
    "            current = min((batch + 1) * dataloader_train.batch_size, len(data_train))\n",
    "            loss = loss.item()\n",
    "            train_acc = calculate_accuracy(predict, dataloader_train)\n",
    "            test_loss, test_acc = calculate_loss_accuracy(predict, dataloader_test, loss_fn)\n",
    "            print(f\"train loss: {loss:>7f}  test loss: {test_loss:>7f}  train accuracy: {train_acc:>3f}  test accuracy: {test_acc:>3f}  [sample {current:>5d}/{len(data_train):>5d}] [epoch {epoch+1:>2d}/{epochs:>2d}]\")\n",
    "            processed_since_log -= log_period"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parametry trénování\n",
    "\n",
    "V předchozím příkladu jsme nejrůznější hyper-parametery modelu \"stříleli od boku\", pojďme se tedy podívat, jaké mohou mít hodnoty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architektura sítě\n",
    "\n",
    "- Počet vrstev\n",
    "- Šířka vrstev\n",
    "- Aktivační funkce\n",
    "    - linear\n",
    "    - tanh\n",
    "    - sigmoid\n",
    "    - hard sigmoid\n",
    "    - relu\n",
    "    - selu\n",
    "    - softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 20))\n",
    "i = 1\n",
    "for activationFunction in [nn.Tanh(), nn.Hardtanh(), nn.Sigmoid(), nn.Hardsigmoid(), nn.ReLU(), nn.LeakyReLU(), nn.SELU(), nn.ELU()]:\n",
    "    plt.subplot(4, 4, i)\n",
    "    i += 1\n",
    "    plt.grid(True)\n",
    "    xs = torch.linspace(-5, 5, 100);\n",
    "    ys = activationFunction(xs)\n",
    "    plt.plot(xs, ys)\n",
    "    plt.title(type(activationFunction).__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ztrátová funkce\n",
    "\n",
    "- Mean square error\n",
    "    $$ \\operatorname{MSE}=\\frac{1}{n}\\sum_{i=1}^n(Y_i-\\hat{Y_i})^2. $$\n",
    "- Hinge\n",
    "    $$ \\operatorname{Hinge} = \\sum_{i=1}^K \\max(0, 1- Y_i \\cdot \\hat{Y_i}) $$\n",
    "- KL divergence\n",
    "    $$ \\operatorname{KL} = - \\sum_{i=1}^K \\hat{Y_i} \\cdot \\log(\\frac{Y_i}{\\hat{Y_i}}) $$\n",
    "- Cross-entropy\n",
    "    $$ \\operatorname{crossentropy} = - \\sum_{i=1}^K Y_i \\cdot \\log(\\hat{Y_i}) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimalizační algoritmus\n",
    "\n",
    "- SGD\n",
    "- RMSProp\n",
    "- Adagrad\n",
    "- Adam\n",
    "- Adadelta\n",
    "- Adamax\n",
    "- Nadam\n",
    "\n",
    "### Learning schedule\n",
    "\n",
    "Volitelně můžeme optimalizační algoritmy doplnit o tzv. weight decay - tj. postupnou změnu learning rate. Například"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_learning_rate = 0.01\n",
    "batch_count = 64\n",
    "optimizer = torch.optim.SGD(model.parameters(), weight_decay=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pro pokročilejší algoritmy typicky není weight decay potřeba, protože mají podobnou funkčnost již zabudovanou."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Postupné používání datasetu\n",
    "\n",
    "To, jak je dataset použit při trénování je určeno 2 parametry\n",
    "\n",
    "- Epochy: kolikrát je celý dataset použit\n",
    "- Batching: Dataset není použit prvek po prvku, ale vždy je najednou trénováno pomocí celé batch (mini-batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Úkol 4\n",
    "\n",
    "Zkuste upravit model na MNISTu a získat co nejlepší přesnost na testovací sadě pomocí výše popsaných parametrů"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tzn",
   "language": "python",
   "name": "tzn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
